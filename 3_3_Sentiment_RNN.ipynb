{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "3-3_Sentiment_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minnji88/NLP-study/blob/main/3_3_Sentiment_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSQVQtQVkMpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5797529-4cb6-4dbf-98d7-f5f7abdc2b1f"
      },
      "source": [
        "#colab 을 이용한 실행시\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDhMi_j7kI8u"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchtext.data as data\n",
        "import torchtext.datasets as datasets\n",
        "import pickle\n",
        "#print (torch.__version__)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHVoD2RfkI81"
      },
      "source": [
        "class RNN_Text(nn.Module):\n",
        "    \n",
        "    def __init__(self, embed_num, class_num):\n",
        "        super(RNN_Text, self).__init__()\n",
        "        V = embed_num\n",
        "        C = class_num\n",
        "        H = 256\n",
        "        \n",
        "        self.embed = nn.Embedding(V, 100)\n",
        "        self.rnn = nn.LSTM(100,H, bidirectional = True)\n",
        "        self.out = nn.Linear(H*2, C)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)  # (N, W, D)\n",
        "        ##x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
        "        x,(_,__) = self.rnn( x, ( self.h, self.c ) )\n",
        "        \n",
        "        logit = self.out(x[-1])\n",
        "        return logit\n",
        "    def inithidden(self,b):\n",
        "        self.h = Variable(torch.randn(2, b, 256))\n",
        "        self.c = Variable(torch.randn(2, b, 256))\n",
        "        "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuVqEcvNkI83"
      },
      "source": [
        "class mydataset(data.Dataset):\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return len(ex.text)\n",
        "    def __init__(self, text_field, label_field, path=None, examples=None, **kwargs):\n",
        "        fields = [('text', text_field), ('label', label_field)]\n",
        "        if examples is None:\n",
        "            path = self.dirname if path is None else path\n",
        "            examples = []\n",
        "            for i,line in enumerate(open(path,'r',encoding='utf-8')):\n",
        "                if i==0:\n",
        "                    continue\n",
        "                line = line.strip().split('\\t')\n",
        "                txt = line[1].split(' ')\n",
        "                #txt= [ d.split('/')[0] for d in line[1].split(' ') ]\n",
        "                examples += [ data.Example.fromlist( [txt, line[2]],fields ) ]\n",
        "        super(mydataset, self).__init__(examples, fields, **kwargs)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-YgsUg5kI86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f72007-b342-490d-dac4-2e57c25acf3a"
      },
      "source": [
        "text_field = data.Field(fix_length=20)\n",
        "#text_field = data.Field()\n",
        "label_field = data.Field(sequential=False, batch_first = True, unk_token = None)\n",
        "\n",
        "train_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/자연어처리수업/nsm/small_ratings_train_tok.txt')\n",
        "\n",
        "test_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/자연어처리수업/nsm/small_ratings_test_tok.txt')\n",
        "\n",
        "text_field.build_vocab(train_data)\n",
        "label_field.build_vocab(train_data)\n",
        "\n",
        "train_iter, test_iter = data.Iterator.splits(\n",
        "                            (train_data, test_data), \n",
        "                            batch_sizes=(100, 1), repeat=False)#, device = -1)\n",
        "len(text_field.vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPOJtjBWkI88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3891bc81-e3e5-4c6c-9976-ad7eac23db90"
      },
      "source": [
        "rnn = RNN_Text(len(text_field.vocab),2)\n",
        "optimizer = torch.optim.Adam(rnn.parameters())\n",
        "rnn.train()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN_Text(\n",
              "  (embed): Embedding(21893, 100)\n",
              "  (rnn): LSTM(100, 256, bidirectional=True)\n",
              "  (out): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HEGfWoiykI8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab187591-8233-4434-bb4d-d0f128b70f6a"
      },
      "source": [
        "%%time\n",
        "for epoch in range(15):\n",
        "    z=0\n",
        "    totalloss = 0\n",
        "    for batch in train_iter:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        txt = batch.text\n",
        "        label = batch.label\n",
        "        #print (txt.size())\n",
        "        rnn.inithidden(txt.size(1))\n",
        "        \n",
        "        pred = rnn(txt)\n",
        "        #print(pred.size(), label.size())\n",
        "        #print(label)\n",
        "        loss = F.cross_entropy(pred, label)\n",
        "        totalloss += loss.data\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(data,label)\n",
        "        \n",
        "    print(epoch,'epoch')  \n",
        "    print(totalloss)\n",
        "    \n",
        "torch.save(rnn,'/content/gdrive/My Drive/자연어처리수업/model/rnn_model.pt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 epoch\n",
            "tensor(69.7482)\n",
            "1 epoch\n",
            "tensor(65.8978)\n",
            "2 epoch\n",
            "tensor(52.4002)\n",
            "3 epoch\n",
            "tensor(41.0379)\n",
            "4 epoch\n",
            "tensor(32.8586)\n",
            "5 epoch\n",
            "tensor(25.6634)\n",
            "6 epoch\n",
            "tensor(18.9274)\n",
            "7 epoch\n",
            "tensor(13.7942)\n",
            "8 epoch\n",
            "tensor(10.1003)\n",
            "9 epoch\n",
            "tensor(7.7004)\n",
            "10 epoch\n",
            "tensor(5.6907)\n",
            "11 epoch\n",
            "tensor(4.9875)\n",
            "12 epoch\n",
            "tensor(3.7874)\n",
            "13 epoch\n",
            "tensor(3.1730)\n",
            "14 epoch\n",
            "tensor(3.0401)\n",
            "CPU times: user 4min 54s, sys: 4.3 s, total: 4min 58s\n",
            "Wall time: 4min 59s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldrqhEt6kI9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b29cd38-0bb2-445e-c88e-ae3a7816a056"
      },
      "source": [
        "%%time\n",
        "from sklearn.metrics import classification_report\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "rnn.eval()\n",
        "y_test = []\n",
        "prediction = []\n",
        "\n",
        "for batch in test_iter:\n",
        "    txt = batch.text\n",
        "    label = batch.label\n",
        "    y_test.append(label.data[0])\n",
        "    \n",
        "    rnn.inithidden(txt.size(1))\n",
        "    \n",
        "    pred = rnn(txt)\n",
        "    _,ans = torch.max(pred,dim=1)\n",
        "    prediction.append(ans.data[0])\n",
        "    \n",
        "    if ans.data[0] == label.data[0]:\n",
        "        correct += 1    \n",
        "    else:\n",
        "        incorrect += 1\n",
        "    \n",
        "print ('correct : ', correct)\n",
        "print ('incorrect : ', incorrect)\n",
        "print(classification_report(torch.tensor(y_test), \n",
        "                            torch.tensor(prediction), \n",
        "                            digits=4, \n",
        "                            target_names=['negative', 'positive']))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct :  87\n",
            "incorrect :  13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.8491    0.9000    0.8738        50\n",
            "    positive     0.8936    0.8400    0.8660        50\n",
            "\n",
            "    accuracy                         0.8700       100\n",
            "   macro avg     0.8713    0.8700    0.8699       100\n",
            "weighted avg     0.8713    0.8700    0.8699       100\n",
            "\n",
            "CPU times: user 745 ms, sys: 122 ms, total: 868 ms\n",
            "Wall time: 1.11 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}